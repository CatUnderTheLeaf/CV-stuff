{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40768ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 18:43:01.043300: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-08 18:43:01.089623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-08 18:43:01.617267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib as mpl\n",
    "from keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2 as cv\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "# path = kagglehub.dataset_download(\"rajkumarl/people-clothing-segmentation\") #CC0: Public Domain\n",
    "# path = kagglehub.dataset_download(\"agrigorev/clothing-dataset-full\") #CC0: Public Domain\n",
    "# path = kagglehub.dataset_download(\"ryanbadai/clothes-dataset\") #MIT\n",
    "# path = kagglehub.dataset_download(\"adisongoh/fashion-clothing-segmentation-dataset\") #CC0: Public Domain\n",
    "# path = kagglehub.dataset_download(\"abeerelmorshedy/fashion-clothes\") #Unknown\n",
    "# path = kagglehub.dataset_download(\"sourabhsingh03993493/clothessegmentation\") #same as \"adisongoh/fashion-clothing-segmentation-dataset\"\n",
    "# path = kagglehub.dataset_download(\"shreyanshverma27/new-data-fashion\") #CC0: Public Domain\n",
    "# path = kagglehub.dataset_download(\"paramaggarwal/fashion-product-images-dataset\") #MIT\n",
    "# path = kagglehub.dataset_download(\"andhikawb/fashion-mnist-png\") #MIT\n",
    "\n",
    "# !mv /home/cat/.cache/kagglehub/datasets/andhikawb/fashion-mnist-png/versions/1 /home/cat/projects/CV-stuff/background_remover/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257ce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /home/cat/.env/tf_env/lib/python3.10/site-packages (1.1.63)\n",
      "Requirement already satisfied: requests-toolbelt in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: cycler in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: six in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: filetype in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: pillow-heif>=0.18.0 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (0.22.0)\n",
      "Requirement already satisfied: certifi in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (2024.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (4.66.4)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (10.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (3.8.4)\n",
      "Requirement already satisfied: idna==3.7 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: python-dotenv in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (1.1.0)\n",
      "Requirement already satisfied: requests in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: python-dateutil in /home/cat/.env/tf_env/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from matplotlib->roboflow) (4.51.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from matplotlib->roboflow) (24.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cat/.env/tf_env/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in I-Style-You-Daily-1 to coco-segmentation:: 100%|██████████| 11234/11234 [00:01<00:00, 6587.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to I-Style-You-Daily-1 in coco-segmentation:: 100%|██████████| 251/251 [00:00<00:00, 9230.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"kp9qURyWHo7oCsHf7ngz\")\n",
    "# project = rf.workspace(\"umut-saydam-03gn7\").project(\"clothescombined\")\n",
    "# version = project.version(3)\n",
    "# dataset = version.download(\"coco-segmentation\")\n",
    "\n",
    "# dataset = version.download(\"sam2\", \"/home/cat/projects/CV-stuff/background_remover/sam2\")\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"kp9qURyWHo7oCsHf7ngz\")\n",
    "# project = rf.workspace(\"wep-7g80m\").project(\"clothing-dcqa4\")\n",
    "# version = project.version(4)\n",
    "# dataset = version.download(\"coco-segmentation\")\n",
    "\n",
    "# project = rf.workspace(\"fashion-7bqvr\").project(\"coco-fpn0s\")\n",
    "# version = project.version(2)\n",
    "# dataset = version.download(\"coco-segmentation\")\n",
    "\n",
    "# project = rf.workspace(\"i-style-you-daily\").project(\"i-style-you-daily\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"coco-segmentation\")\n",
    "                \n",
    "                          \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f14adf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/home/cat/projects/CV-stuff/background_remover/datasets/clothessegmentation\"\n",
    "SET = DATASET_PATH + \"/Test\"\n",
    "IMAGES_PATH = SET + \"/Image/\"\n",
    "MASKS_PATH = SET + \"/Mask/\"\n",
    "\n",
    "NEW_IMAGES_PATH = DATASET_PATH + \"/Image/\"\n",
    "NEW_MASK_PATH = DATASET_PATH + \"/Mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataset with images as masks\n",
    "\n",
    "def transform(path: str, new_path: str):\n",
    "    classes = [0, 17, 19, 20, 41, 47]\n",
    "    if not os.path.exists(new_path): # if there is no exist, make the path\n",
    "        os.makedirs(new_path)\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if filename.endswith(\".png\"):\n",
    "            image = cv.imread(file_path, cv.IMREAD_GRAYSCALE)\n",
    "            # Apply thresholding to create a binary mask\n",
    "            binary_mask = (image < 255).astype(np.uint8)  # Binary mask where 1 represents actual mask and 0 represents whitespace\n",
    "\n",
    "            # Find bounding box of actual mask\n",
    "            nonzero_indices = np.nonzero(binary_mask)\n",
    "            min_row, min_col = np.min(nonzero_indices, axis=1)\n",
    "            max_row, max_col = np.max(nonzero_indices, axis=1)\n",
    "\n",
    "            # Crop the original mask using the bounding box\n",
    "            image = image[min_row:max_row+1, min_col:max_col+1]\n",
    "            clothes_mask = np.where((image > 60) & (image < 150), 1, 0).astype(np.uint8)\n",
    "            mask_image = np.repeat(clothes_mask[:, :, np.newaxis], 3, 2)\n",
    "            cv.imwrite(new_path + filename.split(\".\")[0]+\".png\", mask_image)\n",
    "            # plt.imshow(image, cmap=\"gray\")\n",
    "        else:\n",
    "            image = cv.imread(file_path, cv.IMREAD_COLOR)\n",
    "            cv.imwrite(new_path + filename.split(\".\")[0]+\".png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform(IMAGES_PATH, NEW_IMAGES_PATH)\n",
    "# transform(MASKS_PATH, NEW_MASK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2c54ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform sam2 datasest with labels in coco annotation file file \n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "COCO_DATASET_PATH = \"/home/cat/projects/CV-stuff/background_remover/datasets/COCO-2\"\n",
    "SET = COCO_DATASET_PATH + \"/train\"\n",
    "\n",
    "NEW_MASK_PATH = COCO_DATASET_PATH + \"/Mask/\"\n",
    "NEW_IMAGE_PATH = COCO_DATASET_PATH + \"/Image/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc48ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coco(path: str, new_mask_path: str, new_image_path: str):\n",
    "    if not os.path.exists(new_mask_path): # if there is no exist, make the path\n",
    "        os.makedirs(new_mask_path)\n",
    "    if not os.path.exists(new_image_path): # if there is no exist, make the path\n",
    "        os.makedirs(new_image_path)\n",
    "# Load your COCO annotations file\n",
    "    coco = COCO(path+\"/_annotations.coco.json\")\n",
    "\n",
    "    # Loop through images\n",
    "    for img_id in coco.getImgIds():\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        height, width = img_info[\"height\"], img_info[\"width\"]\n",
    "        # print(img_info[\"file_name\"][:-4])\n",
    "        anns = coco.loadAnns(coco.getAnnIds(imgIds=img_id))\n",
    "\n",
    "        # Create empty mask\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        for i, ann in enumerate(anns, 1):\n",
    "            # Flattened polygon points from ann[\"segmentation\"][0]\n",
    "            polygon = ann[\"segmentation\"][0]\n",
    "\n",
    "            # Convert to NumPy array and reshape to (N, 1, 2) for OpenCV\n",
    "            pts = np.array(polygon, dtype=np.int32).reshape(-1, 1, 2)\n",
    "\n",
    "            # Fill polygon with value 1\n",
    "            cv.fillPoly(mask, [pts], color=1)\n",
    "            # binary_mask = maskUtils.decode(rle)\n",
    "            # mask[binary_mask[:, :, 0] > 0] = 1\n",
    "\n",
    "        # Save mask\n",
    "        mask_img = Image.fromarray(mask)\n",
    "        mask_img.save(new_mask_path + img_info[\"file_name\"][:-4] + \".png\")\n",
    "        png_image = Image.open(path+\"/\"+img_info[\"file_name\"])\n",
    "        png_image.save(new_image_path + img_info[\"file_name\"][:-4] + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d6d33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "transform_coco(SET, NEW_MASK_PATH, NEW_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c39289",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(\"/home/cat/projects/CV-stuff/background_remover/datasets/clothing-dataset-full/results/mask/00a1b7a8-217d-45bf-93a8-86db0bdf9d9d.png\", cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfdd3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   5  11  18  24  37  82 127 172 218 243 246\n",
      " 249 251 254 254 254 254 254 254 254 254 254 254 255 255 255 255 255 255\n",
      " 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      " 255 255 255 255 255 255 255 255 255 255 255 255]\n"
     ]
    }
   ],
   "source": [
    "np.unique(image)\n",
    "image.shape\n",
    "print(image[2000][200:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c382c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/home/cat/projects/CV-stuff/background_remover/datasets/clothing-dataset-full/results/Image\"\n",
    "NEW_PATH = \"/home/cat/projects/CV-stuff/background_remover/datasets/clothing-dataset-full/resized/Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c10fdda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform masks where mask is not strictly 0 and 1\n",
    "\n",
    "def transform_to_binary(path: str, new_path: str):\n",
    "    if not os.path.exists(new_path): # if there is no exist, make the path\n",
    "        os.makedirs(new_path)\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        image = cv.imread(file_path, cv.IMREAD_COLOR)\n",
    "\n",
    "        # binary_mask = np.where((image > 0), 1, 0).astype(np.uint8)\n",
    "        # mask_image = np.repeat(binary_mask[:, :, np.newaxis], 3, 2)\n",
    "        # Resize\n",
    "        # Define the new width\n",
    "        new_width = 640\n",
    "\n",
    "        # Calculate the new height while maintaining the aspect ratio\n",
    "        height, width = image.shape[:2]\n",
    "        aspect_ratio = width / height\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "        image = cv.resize(image, (new_width, new_height), interpolation=cv.INTER_NEAREST)\n",
    "        # print(os.path.join(new_path, filename), mask_image.shape, image.shape)\n",
    "        cv.imwrite(os.path.join(new_path, filename), image)\n",
    "\n",
    "transform_to_binary(DATASET_PATH, NEW_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
